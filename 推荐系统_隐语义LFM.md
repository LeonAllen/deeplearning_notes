推荐阅读:[美团“猜你喜欢”深度学习排序模型实践](https://tech.meituan.com/recommend_dnn.html)
#

一、隐语义模型的基本思想
#
<br>前言：隐语义模型是最近几年来推荐系统领域一个较为热门
<br>引例：假设用户A喜欢《操作系统》，用户B喜欢《简爱》，现在系统要对用户A和用户B推荐其他书籍。基于 UserCF(基于用户的协同过滤)，找到与他们偏好相似的用户，将相似用户偏好的书籍推荐给他们；基于ItemCF(基于物品的协同过滤)，找到与他们 当前偏好书籍相似的其他书籍，推荐给他们。其实还有一种思路，就是根据用户的当前偏好信息，得到用户的兴趣偏好，将该类兴趣对应的物品推荐给当前用户。比 如，用户A喜欢的《操作系统》属于计算机类的书籍，那我们可以将其他的计算机类书籍推荐给用户A；用户B喜欢的是文学类数据，可将《巴黎圣母院》等这 类文字作品推荐给用户B。这就是隐语义模型，依据“兴趣”这一隐含特征将用户与物品进行连接，需要说明的是此处的“兴趣”其实是对物品类型的一个分类而已。


二、隐语义模型的数学理解
#
<br> 如下图所示，R矩阵是用户对于各个物品的偏好程度(Rij表示的是user_i对于item_j的喜好程度),P矩阵是用户对于不同物品类别的兴趣程度(pij表示的是user_i对于class_j的喜好程度)，Q矩阵代表某物品属于不同类别的权重。实际上我们需要根据用户当前的物品偏好信息R进行计算，从而得到对应的矩阵P和矩阵Q。
![](https://github.com/LeonAllen/deeplearning_notes/blob/master/image/Rpq1.jpg)  


三、隐语义模型所解决的问题
#
<br>1、如何对物品进行分类？
##

<br>2、如何确定用户对哪些类别有兴趣及其兴趣程度？
##
<br>3、对于一个给定的类别，选择此类别中哪些物品进行推荐，如何确定物品在某个类别中的权重？
##
<br>隐语义模型是基于用户的行为数据进行自动聚类，反映出用户对物品的分类意见。
<br>指定物品聚类的类别数k，k越大，粒度越细。
<br>根据用户的行为数据来计算出物品在各个类别中的权重
<br>隐语义模型得到的物品类别不是基于同一个维度的，维度是由用户的共同兴趣决定的


四、隐语义模型的样本问题
#
隐语义模型在显性反馈数据上能解决评分预测问题并达到了很好的精度。不过推荐系统主要讨论的是隐形反馈数据，这种数据集的特点是只知道用户喜欢什么，却不知道用户不喜欢什么。那么，在隐形反馈数据集上应用隐语义模型解决推荐的第一个关键问题就是如何给每个用户生成负样本(不感兴趣的内容)。对负样本采样时，应遵循以下原则:
<br>对每个用户，要保证正负样本的平衡
<br>对用户采负样本的时候，选择热门且用户没什么行为的物品。(因为很热门但用户没有行为，在一定程度上表示用户对此不感兴趣。反之，如果冷门且没有行为的话，可能只是用户不知道这个物品，感兴趣与否无法判断。)

五、隐语义模型的推导思路
#
隐语义模型是根据下图公式来计算用户U对于物品I的兴趣度。
![](https://github.com/LeonAllen/deeplearning_notes/blob/master/image/6983817-b97d5138cb501649.jpg)  
其中，隐语义模型会把物品分成k个类型，这个是我们根据经验和业务知识进行反复尝试决定的。p(u,k)表示用户u对于第k个分类的喜爱程度(1<k<=K),q(k,i)表示物品i属于第k个分类的权重(1<k<=K)。

<br>如何计算矩阵P和矩阵Q中的参数值呢? 一般做法就是最优化损失函数来求参数。
<br>损失函数如下所示：
![](https://github.com/LeonAllen/deeplearning_notes/blob/master/image/6983817-b97d5138cb501649.jpg) 
<br>上式中的
![](https://github.com/LeonAllen/deeplearning_notes/blob/master/image/6983817-56a772f151291e11.jpg) 
<br>是用来防止过拟合的正则化项，λ需要根据具体应用场景反复实验得到。损失函数的意义是用户u对物品i的真实喜爱程度与推算出来的喜爱程度的均方根误差，通俗 来说就是真实的喜爱程度与推算的喜爱程度的误差，要使模型最合理当然就是使这个误差达到最小值。公式中最后两项是惩罚因子，用来防止分类数取得过大而使误 差减少的不合理做法的发生，λ参数是一个常数，需要根据经验和业务知识进行反复尝试决定的。
<br>
<br>损失函数的优化使用随机梯度下降算法，这里不做介绍。
<br>在隐语义模型中，重要的参数有以下4个：

1）隐分类的个数F；

2）梯度下降过程中的步长(学习速率)α；

3）损失函数中的惩罚因子λ；

4）正反馈样本数和负反馈样本数的比例ratio；

六、LFM缺陷
#
隐语义模型在实际使用中有一个困难，那就是它很难实现实时推荐。经典的隐语义模型每次训练时都需要扫描所有的用户行为记录，这样才能计算出用户对于 每个隐分类的喜爱程度矩阵P和每个物品与每个隐分类的匹配程度矩阵Q。而且隐语义模型的训练需要在用户行为记录上反复迭代才能获得比较好的性能，因此 LFM的每次训练都很耗时，一般在实际应用中只能每天训练一次，并且计算出所有用户的推荐结果。从而隐语义模型不能因为用户行为的变化实时地调整推荐结果 来满足用户最近的行为。
